{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Dropout, Activation  \n",
    "from keras.optimizers import SGD  \n",
    "from keras.datasets import mnist  \n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrust network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500,input_shape=(784,))) # 输入层，28*28=784  \n",
    "model.add(Activation('tanh')) # 激活函数是tanh  \n",
    "model.add(Dropout(0.5)) # 采用50%的dropout\n",
    "\n",
    "model.add(Dense(500)) # 隐藏层节点500个  \n",
    "model.add(Activation('tanh'))  \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10)) # 输出结果是10个类别，所以维度是10  \n",
    "model.add(Activation('softmax')) # 最后一层用softmax作为激活函数\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haile\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # 优化函数，设定学习率（lr）等参数  \n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd) # 使用交叉熵作为loss函数\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # 使用Keras自带的mnist工具读取数据（第一次需要联网）\n",
    "# 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mreshape(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]) \n\u001b[0;32m      2\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mreshape(X_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], X_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m X_test\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])  \n\u001b[0;32m      3\u001b[0m Y_train \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39marange(\u001b[39m10\u001b[39m) \u001b[39m==\u001b[39m y_train[:, \u001b[39mNone\u001b[39;00m])\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m) \n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])  \n",
    "Y_train = (np.arange(10) == y_train[:, None]).astype(int) \n",
    "Y_test = (np.arange(10) == y_test[:, None]).astype(int)\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3)\n",
    "model.evaluate(X_test, Y_test, batch_size=200, verbose=0)\n",
    "'''\n",
    ".fit的一些参数\n",
    "batch_size：对总的样本数进行分组，每组包含的样本数量\n",
    "epochs ：训练次数\n",
    "shuffle：是否把数据随机打乱之后再进行训练\n",
    "validation_split：拿出百分之多少用来做交叉验证\n",
    "verbose：屏显模式 0：不输出  1：输出进度  2：输出每次的训练结果\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2478586733341217"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = (np.arange(10) == y_train[:, None]).astype(int) \n",
    "Y_test = (np.arange(10) == y_test[:, None]).astype(int)\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3)\n",
    "model.evaluate(X_test, Y_test, batch_size=200, verbose=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set\n",
      "\n",
      "The test loss is 0.247859\n",
      "\n",
      "The accuracy of the model is 0.925400\n"
     ]
    }
   ],
   "source": [
    "print(\"test set\")\n",
    "scores = model.evaluate(X_test,Y_test,batch_size=200,verbose=0)\n",
    "print(\"\")\n",
    "print(\"The test loss is %f\" % scores)\n",
    "result = model.predict(X_test,batch_size=200,verbose=0)\n",
    "\n",
    "result_max = np.argmax(result, axis = 1)\n",
    "test_max = np.argmax(Y_test, axis = 1)\n",
    "\n",
    "result_bool = np.equal(result_max, test_max)\n",
    "true_num = np.sum(result_bool)\n",
    "print(\"\")\n",
    "print(\"The accuracy of the model is %f\" % (true_num/len(result_bool)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eeb0b4a1f1fc5ab215c7c5c64754f775acea0a93fdff470701699d5ccb4b9670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
